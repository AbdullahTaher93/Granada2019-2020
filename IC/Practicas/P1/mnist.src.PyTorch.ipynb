{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ejemplo adaptado de los tutoriales https://medium.com/apache-mxnet/mxnet-for-pytorch-users-in-10-minutes-a7353863406a, https://mxnet.apache.org/api/python/docs/tutorials/getting-started/to-mxnet/pytorch.html y https://nextjournal.com/gkoehler/pytorch-mnist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la biblioteca PyTorch, para lo cual hemos de instalarla previamente (junto con NumPy en caso de que no lo tengamos ya en nuestro sistema). \n",
    "\n",
    "Usando `pip`, ejecutamos el siguiente comando:\n",
    "\n",
    "`pip3 install torch==1.2.0+cpu torchvision==0.4.0+cpu -f https://download.pytorch.org/whl/torch_stable.html` \n",
    "\n",
    "Si disponemos de GPU en nuestro ordenador, podemos aprovecharla instalando la versión de MXNet con soporte para GPU:\n",
    "\n",
    "`pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html`\n",
    "\n",
    "si estamos utilizando la versión 9.2 de CUDA, o bien\n",
    "\n",
    "`pip3 install torch===1.2.0 torchvision===0.4.0 -f https://download.pytorch.org/whl/torch_stable.html`\n",
    "\n",
    "si tenemos instalada la versión 10 de CUDA. Si en nuestro ordenador tenemos otra versión diferente de CUDA, tendremos que seleccionar la versión adecuada de PyTorch tal como se indica en la web: https://pytorch.org/get-started/locally.\n",
    "\n",
    "Cuando tengamos todo en orden, ya podemos utilizar PyTorch desde Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos con una comprobación de la versión que hemos instalado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0+cu92\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no se ha producido ningún error al ejecutar la línea anterior, podemos empezar a trabajar con PyTorch en nuestro ordenador. Para que los experimentos sean reproducibles, podemos establecer la semilla del generador de números pseudoaleatorios..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c0002d5770>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)  # Semilla del generador de números aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar si estamos utilizando CUDA desde PyTorch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "GeForce GT 755M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python363-64\\lib\\site-packages\\torch\\cuda\\__init__.py:132: UserWarning: \n",
      "    Found GPU0 GeForce GT 755M which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.device_count()==1:\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El conjunto de datos MNIST\n",
    "\n",
    "Descargamos el conjunto de datos MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3181,))])\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(datasets.MNIST('files/', \n",
    "    train=True, download=True, transform=trans),\n",
    "    batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "test_data = torch.utils.data.DataLoader(datasets.MNIST('files/', \n",
    "    train=False, download=True, transform=trans),\n",
    "    batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores 0.1307 y 0.3081 utilizados en la normalización corresponden a la media y la desviación estándar del conjunto de datos MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra primera red neuronal en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestros experimentos con PyTorch, utilizaremos el paquete `nn` de PyTorch en el que ya se definen distintos tipos de capas para redes neuronales artificiales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as pt_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestra red neuronal multicapa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la red neuronal\n",
    "\n",
    "network = pt_nn.Sequential(\n",
    "    pt_nn.Linear(28*28, 256),\n",
    "    pt_nn.ReLU(),\n",
    "    pt_nn.Linear(256, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especificamos la función de pérdida y el algoritmo de optimización que vamos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = pt_nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(network.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, entrenamos la red recorriendo una y otra vez el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, avg loss 0.3260, time 5.81\n",
      "epoch 1, avg loss 0.1514, time 5.43\n",
      "epoch 2, avg loss 0.1078, time 5.47\n",
      "epoch 3, avg loss 0.0831, time 5.41\n",
      "epoch 4, avg loss 0.0677, time 5.43\n",
      "epoch 5, avg loss 0.0568, time 5.46\n",
      "epoch 6, avg loss 0.0481, time 5.59\n",
      "epoch 7, avg loss 0.0414, time 5.56\n",
      "epoch 8, avg loss 0.0357, time 5.73\n",
      "epoch 9, avg loss 0.0309, time 6.68\n",
      "Wall time: 56.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = .0\n",
    "    tic = time.time()\n",
    "    for X, y in train_data:\n",
    "        trainer.zero_grad()\n",
    "        loss = loss_function(network(X.view(-1, 28*28)), y)\n",
    "        loss.backward()\n",
    "        trainer.step()\n",
    "        total_loss += loss.mean()\n",
    "    print('epoch %d, avg loss %.4f, time %.2f' % (\n",
    "        epoch, total_loss/len(train_data), time.time()-tic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras unos segundos, obtenemos una red entrenada capaz de clasificar correctamente más del 90% de los ejemplos del conjunto de entrenamiento de MNIST, algo que comprobamos sobre el conjunto de prueba de MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0005, Accuracy: 9806/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "network.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_data:\n",
    "        output = network(data.view(-1, 28*28))\n",
    "        test_loss += loss_function(output, target)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_data.dataset)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_data.dataset), 100. * correct / len(test_data.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo ha ido bien, habremos obtenido una red capaz de clasificar correctamente sobre el 98% de los ejemplos del conjunto de prueba de MNIST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
