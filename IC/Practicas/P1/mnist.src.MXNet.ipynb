{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ejemplo adaptado del tutorial https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la biblioteca MXNet, para lo cual hemos de instalarla previamente. En una instalación de Python de 64 bits, ejecutamos el siguiente comando:\n",
    "\n",
    "`pip3 install --upgrade mxnet` \n",
    "\n",
    "Si disponemos de GPU en nuestro ordenador, podemos aprovecharla instalando la versión de MXNet con soporte para GPU:\n",
    "\n",
    "`pip3 install --upgrade mxnet-cu101`\n",
    "\n",
    "La versión indica que estamos instalando MXNet con CUDA/CuDNN usando la versión 10.1 de CUDA. Si en nuestro ordenador tenemos otra versión diferente de CUDA (p.ej. CUDA 9.2), tendremos que seleccionar la versión adecuada de MXNet (`mxnet-cu92`) tal como se indica en la web de MXNet: https://mxnet.io/get_started.\n",
    "\n",
    "Cuando tengamos todo en orden, ya podemos utilizar MXNet desde Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos con una comprobación de la versión que hemos instalado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "print (mx.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no se ha producido ningún error al ejecutar la línea anterior, podemos empezar a trabajar con MXNet en nuestro ordenador. Para que los experimentos sean reproducibles, podemos establecer la semilla del generador de números pseudoaleatorios..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.random.seed(42)  # Semilla del generador de números aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El conjunto de datos MNIST\n",
    "\n",
    "Descargamos el conjunto de datos MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y creamos dos iteradores para recorrer tanto el conjunto de entrenamiento como el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data = mx.io.NDArrayIter(mnist['train_data'], mnist['train_label'], batch_size, shuffle=True)\n",
    "val_data = mx.io.NDArrayIter(mnist['test_data'], mnist['test_label'], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra primera red neuronal en MXNet Gluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestros experimentos con MXNet, utilizaremos el paquete Gluon, que proporciona un API de alto nivel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestra red neuronal multicapa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la red neuronal\n",
    "\n",
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(256, activation='relu'))\n",
    "    net.add(nn.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especificamos el contexto en el que ejecutaremos nuestro algoritmo (usando la GPU si está disponible):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = mx.test_utils.list_gpus()\n",
    "ctx =  [mx.gpu()] if gpus else [mx.cpu(0), mx.cpu(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos nuestra red neuronal y el algoritmo de optimización que vamos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, entrenamos la red recorriendo una y otra vez el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc at epoch 0: accuracy=0.876566\n",
      "training acc at epoch 1: accuracy=0.927689\n",
      "training acc at epoch 2: accuracy=0.943014\n",
      "training acc at epoch 3: accuracy=0.951976\n",
      "training acc at epoch 4: accuracy=0.959188\n",
      "training acc at epoch 5: accuracy=0.964003\n",
      "training acc at epoch 6: accuracy=0.968650\n",
      "training acc at epoch 7: accuracy=0.971782\n",
      "training acc at epoch 8: accuracy=0.974097\n",
      "training acc at epoch 9: accuracy=0.976596\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "# Use Accuracy as the evaluation metric.\n",
    "metric = mx.metric.Accuracy()\n",
    "softmax_cross_entropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "for i in range(epoch):\n",
    "    # Reset the train data iterator.\n",
    "    train_data.reset()\n",
    "    # Loop over the train data iterator.\n",
    "    for batch in train_data:\n",
    "        # Splits train data into multiple slices along batch_axis\n",
    "        # and copy each slice into a context.\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "        # Splits train labels into multiple slices along batch_axis\n",
    "        # and copy each slice into a context.\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = []\n",
    "        # Inside training scope\n",
    "        with ag.record():\n",
    "            for x, y in zip(data, label):\n",
    "                z = net(x)\n",
    "                # Computes softmax cross entropy loss.\n",
    "                loss = softmax_cross_entropy_loss(z, y)\n",
    "                # Backpropagate the error for one iteration.\n",
    "                loss.backward()\n",
    "                outputs.append(z)\n",
    "        # Updates internal evaluation\n",
    "        metric.update(label, outputs)\n",
    "        # Make one step of parameter update. Trainer needs to know the\n",
    "        # batch size of data to normalize the gradient by 1/batch_size.\n",
    "        trainer.step(batch.data[0].shape[0])\n",
    "    # Gets the evaluation result.\n",
    "    name, acc = metric.get()\n",
    "    # Reset evaluation result to initial state.\n",
    "    metric.reset()\n",
    "    print('training acc at epoch %d: %s=%f'%(i, name, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras unos segundos, obtenemos una red entrenada capaz de clasificar correctamente más del 90% de los ejemplos del conjunto de entrenamiento de MNIST. Sin embargo, lo que nos interesa es comprobar su capacidad predictiva sobre el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: accuracy=0.972013\n"
     ]
    }
   ],
   "source": [
    "# Use Accuracy as the evaluation metric.\n",
    "metric = mx.metric.Accuracy()\n",
    "# Reset the validation data iterator.\n",
    "val_data.reset()\n",
    "\n",
    "# Loop over the validation data iterator.\n",
    "for batch in val_data:\n",
    "    # Splits validation data into multiple slices along batch_axis\n",
    "    # and copy each slice into a context.\n",
    "    data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "    # Splits validation label into multiple slices along batch_axis\n",
    "    # and copy each slice into a context.\n",
    "    label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "    outputs = []\n",
    "    for x in data:\n",
    "        outputs.append(net(x))\n",
    "    # Updates internal evaluation\n",
    "    metric.update(label, outputs)\n",
    "\n",
    "print('validation acc: %s=%f'%metric.get())\n",
    "# assert metric.get()[1] > 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo ha ido bien, habremos obtenido una red capaz de clasificar correctamente sobre el 97% de los ejemplos del conjunto de prueba de MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
